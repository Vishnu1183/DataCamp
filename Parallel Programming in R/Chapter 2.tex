##########################  The parallel Package   ##################

##### Exploring the cluster object
# Load the parallel package
library(parallel)

# Make a cluster with 4 nodes
cl <- makeCluster(4)

# Investigate the structure of cl
str(cl)

# What is the process ID of the workers?
clusterCall(cl, Sys.getpid)

# Stop the cluster
stopCluster(cl)


##### Socket vs. Fork (I) ---1
# A global variable and a print function are defined
a_global_var <- "before"
print_global_var <- function() print(a_global_var)

# Create a socket cluster with 2 nodes
cl_sock <- makeCluster(2, type = "PSOCK")

# Evaluate the print function on each node
  clusterCall(cl_sock,print_global_var)

# Stop the cluster
stopCluster(cl_sock)


##### Socket vs. Fork (I) ---2
# A global variable and a print function are defined
a_global_var <- "before"
print_global_var <- function() print(a_global_var)

# Create a fork cluster with 2 nodes
cl_fork <- makeCluster(2, "FORK")

# Evaluate the print function on each node
clusterCall(cl_fork,print_global_var)

# Change the global var to "after"
a_global_var <- 'after'

# Evaluate the print fun on each node again
clusterCall(cl_fork,print_global_var)

# Stop the cluster
stopCluster(cl_fork)


##### Socket vs. Fork (II)
A and C


##### Benchmarking setup --1
# Wrap this code into a function
mean_of_rnorm_sequentially <- function(n_numbers_per_replicate,n_replicates)
{
n <- rep(n_numbers_per_replicate, n_replicates)
lapply(n, mean_of_rnorm)
}

# Call it to try it
mean_of_rnorm_sequentially(1000, 5)


##### Benchmarking setup --2
# Wrap this code into a function
mean_of_rnorm_in_parallel <- function(n_numbers_per_replicate,n_replicates){
n <- rep(n_numbers_per_replicate, n_replicates)
clusterApply(cl, n, mean_of_rnorm) 
}

# Call it to try it
mean_of_rnorm_in_parallel(1000, 5)


##### Task size matters  -- 1
# Set numbers per replicate to 5 million
n_numbers_per_replicate <- 5000000

# Set number of replicates to 4
n_replicates <- 4

# Run a microbenchmark
microbenchmark(
  # Call mean_of_rnorm_sequentially()
  mean_of_rnorm_sequentially(n_numbers_per_replicate, n_replicates), 
  # Call mean_of_rnorm_in_parallel()
  mean_of_rnorm_in_parallel(n_numbers_per_replicate, n_replicates),
  times = 1, 
  unit = "s"
)

##### Task size matters  -- 2
# Change the numbers per replicate to 100
n_numbers_per_replicate <- 100

# Change number of replicates to 100
n_replicates <- 100

# Rerun the microbenchmark
microbenchmark(
  mean_of_rnorm_sequentially(n_numbers_per_replicate, n_replicates), 
  mean_of_rnorm_in_parallel(n_numbers_per_replicate, n_replicates),
  times = 1, 
  unit = "s"
)

##### Loading package on nodes --1
# Pre-defined myrdnorm 
myrdnorm <- function(n, mean = 0, sd = 1) 
    rdnorm(n, mean = mean, sd = sd)

# Parameters
n_numbers_per_replicate <- 1000
n_replicates <- 20

# Repeat n_numbers_per_replicate, n_replicates times
n <- rep(n_numbers_per_replicate,n_replicates)

# Load extraDistr on master
library(extraDistr)

# Run myrdnorm in parallel. This should fail!
res <- clusterApply(cl,x = n, myrdnorm)


##### Loading package on nodes --2
# From previous step
myrdnorm <- function(n, mean = 0, sd = 1) 
    rdnorm(n, mean = mean, sd = sd)
n_numbers_per_replicate <- 1000
n_replicates <- 20
n <- rep(n_numbers_per_replicate, n_replicates)

# Load extraDistr on master
library(extraDistr)

# Load extraDistr on all workers
clusterEvalQ(cl, library(extraDistr))

# Run myrdnorm in parallel. It should work now!
res <- clusterApply(cl, x = n,myrdnorm)

# Plot the result
plot(table(unlist(res)))


##### Setting global variables --1
# rdnorm(), but using global variables
myrdnorm <- function(n) {
  rdnorm(n, mean = mean, sd = sd)
}

# Set mean to 10, globally
mean <- 10

# Set sd to 5, globally
sd <- 5

# Generate 1000 numbers with myrdnorm()
myrdnorm(1000)



##### Setting global variables -- 2
# From previous step
myrdnorm <- function(n) {
  rdnorm(n, mean = mean, sd = sd)
}

# Set number of numbers to generate
n <- rep(1000, 20)

# Run an expression on each worker
clusterEvalQ(
  cl, {
    # Load extraDistr
    library(extraDistr)
    # Set mean to 10
    mean <- 10
    # Set sd to 5
    sd <- 5
})

# Run myrdnorm in parallel
res <- clusterApply(cl,x = rep(1000,20),myrdnorm)

# Plot the results
plot(table(unlist(res)))


#####   Exporting global objects
# Set global objects on master: mean to 20, sd to 10
mean <- 20
sd <- 10

# Load extraDistr on workers
clusterEvalQ(cl, library(extraDistr))

# Export global objects to workers
clusterExport(cl, c("mean", "sd"))

# Run myrdnorm in parallel
res <- clusterApply(cl, n, myrdnorm)

# Plot the results
plot(table(unlist(res)))



##### Passing data as arguments -- 1
# Remind yourself how select_words() works
select_words

# Select words beginning with "v", at least 10 letters long
words_v10 <- select_words(words,"v",10)

# Get the unique words
unique(words_v10)


##### Passing data as arguments -- 2
# Generate 2 random groups
groups <- sample(2, length(words), replace = TRUE)

# See those groups
head(groups, 20)

# Split words into groups
split_words <- split(words, groups)


##### Passing data as arguments -- 3
# From previous step
groups <- sample(2, length(words), replace = TRUE)
split_words <- split(words, groups)
                      
# Apply select_words() to each element of split_words in parallel
res <- clusterApply(cl,split_words,  select_words, letter = 'v', min_length = 10)
 
# Flatten the result
words_v10 <- unlist(res)

# Get the unique words
unique(words_v10)



##### Chunking migration application on worker's side
# Export data and functions
clusterExport(cl, c("ar1est", "ar1_one_trajectory", "ar1_block_of_trajectories"))

# Process ar1_multiple_blocks_of_trajectories in parallel
res <- clusterApply(cl, 1:nrow(ar1est), 
                    fun = ar1_multiple_blocks_of_trajectories)
                    
# Combine results into a matrix and show results        
trajs <- do.call(rbind, res)
show_migration(trajs)


##### Alternative chunking
# Split task into 5 chunks
ind <- splitIndices(nrow(ar1est), 5)

# Process ar1_multiple_blocks_of_trajectories in parallel
res <- clusterApply(cl, ind, ar1_multiple_blocks_of_trajectories)

# Compare the structure of the results 
str(res)
str(res_prev)

